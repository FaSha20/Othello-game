{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e641a47",
   "metadata": {},
   "source": [
    "<H2 style=\"color:blue;font-size:20px;\"align=\"right\">فاطمه شاه حسینی</H2>\n",
    " \n",
    " <H2 style=\"color:blue;font-size:20px;\"align=\"right\"> 810199440 </H2>\n",
    " <H2 style=\"color:blue;font-size:20px;\"align=\"right\"> (بازی خصمانه)   تمرین کامپیوتری شماره دو </H2>\n",
    " <H2 style=\"color:green;font-size:20px;\"align=\"right\"> هدف: </H2>\n",
    " <H2 style=\"color:black;font-size:15px;\"align=\"right\">   پیاده سازی بازی اتلو با الگوریتم مینی مکس و بررسی تاثیر عمق الگوریتم و هرس کردن در زمان اجرا و تعداد نود های دیده شده  </H2>\n",
    " <H2 style=\"color:green;font-size:20px;\"align=\"right\"> توضیح کلی پروژه: </H2>\n",
    "  <H2 style=\"color:black;font-size:15px;\"align=\"right\">  در این بازی حریف ما کامپیوتر است که هر بار به طور رندوم یکی از گزینه های ممکنه اش را بازی می کند، و ما در مقابل با انجام الگوریتم مینی مکس با طول عمق مشخص بهترین حرکتی که می توانیم را انجام می دهیم و در نهایت در 100 تا 200 بار اجرای بازی، مقایسه می کنیم که این هوشمندی در انتخاب گزینه های حرکت چقدر به برد ما کمک کرده است</H2>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73932de",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\">آیا می توان فرزندان را طوری انتخاب کرد که بیشترین مقدار هرس را داشته باشیم؟ </H3>\n",
    "<H3 style=\"color:black;font-size:20px;\"align=\"right\">اگر فرزندان در استیت های ماکس کننده به ترتیب کاهشی امتیاز قرار گرفته باشند و ابتدا فرزند با امتیاز بیشتر بررسی شود، احتمال اینکه از بتا بزرگتر باشد بیشتر است و بنابراین احتمال هرس شدن بقیه شاخه افزایش می یابد . به طور مشابه در استیت های مینیمم کننده بهتر است که ابتدا فرزندان با امتیاز کوچکتر بررسی شوند که احتمال کوچکتر از آلفا بودن انها بیشتر و به تبعش احتمال هرس شدن شاخه افزایش بیابد. در این مساله بازی هم برای بررسی امتیاز هر فرزند در سورت کردن فرزندان از تابع محاسبه اولویت استفاده می شود که فرزندان را از امتیاز بیشتر به کمتر برمی گرداند.  </H3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddab921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prioritiy(self,key):\n",
    "        i, j = key\n",
    "        for x in [0, 5]:\n",
    "            for y in [0, 5]:\n",
    "                if (i,j) == (x,y):\n",
    "                    return 1\n",
    "            for y in [1,2,3,4]:\n",
    "                if (i,j) == (x,y) or (i,j) == (y,x):\n",
    "                    return 2\n",
    "        return 3\n",
    "    \n",
    "def get_valid_moves(self, player):\n",
    "        moves = set()\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if self.board[i][j] == 0:\n",
    "                    for di in [-1, 0, 1]:\n",
    "                        for dj in [-1, 0, 1]:\n",
    "                            if di == 0 and dj == 0:\n",
    "                                continue\n",
    "                            x, y = i, j\n",
    "                            captured = []\n",
    "                            while 0 <= x + di < self.size and 0 <= y + dj < self.size and self.board[x + di][\n",
    "                                    y + dj] == -player:\n",
    "                                captured.append((x + di, y + dj))\n",
    "                                x += di\n",
    "                                y += dj\n",
    "                            if 0 <= x + di < self.size and 0 <= y + dj < self.size and self.board[x + di][\n",
    "                                    y + dj] == player and len(captured) > 0:\n",
    "                                moves.add((i, j))\n",
    "        moves = list(moves)\n",
    "#         moves.sort(key=self.calc_prioritiy)\n",
    "        return moves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b27a6",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\">برنچینگ فاکتور در این بازی با پیشرفت بازی چه تغییری می کند؟ </H3>\n",
    "<H3 style=\"color:black;font-size:20px;\"align=\"right\">برنچینگ فاکتور در این بازی در حقیقت تعداد حرکت هایی است که هر فرد می تواند در هر استیت از بازی انجام دهد و بسته به روند بازی ممکن است زیاد یا کم شود.در مواقعی که برنچینگ فاکتور خیلی زیاد است، فضای جست و جو بسیار بزرگ می شود و حافظه و زمان زیادی مصرف می شود. </H3>\n",
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\">چرا در هرس کردن بدون از دست رفتن دقت، الگوریتم سریع می شود؟ </H3>\n",
    "<H3 style=\"color:black;font-size:20px;\"align=\"right\">چون در هرس کردن تنها حرکت هایی که وضعیت امتیاز ما را افزایش نمی دهند، از ابتدا و قبل از بررسی حذف می کنیم و مطمینا حرکت های بهینه ای که جزو استراتژی برد ما هستند را حذف نمی کنیم. پس دقت ثابت می ماند ولی زمان اجرا کاهش می یابد. </H3>\n",
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\">چرا وقتی حریف بهینه بازی نمی کند، استفاده از مینی مکس راه حل بهینه نیست؟  </H3>\n",
    "<H3 style=\"color:black;font-size:20px;\"align=\"right\"> چون در مینی مکس با فرض اینکه حریف هم مانند ما بهینه عمل می کند، در بعضی مواقع امتیاز زیادی را از دست داده ایم درحالیکه با احتمال خوبی حریف بعد از حرکت حریصانه ما به سمت امتیاز بیشتر، حرکت بهینه اش را انجام نمی داده و با وارد کردن عنصر شانس به مساله ما می توانستیم زودتر به پیروزی برسیم یا امتیاز بیشتری نسبت به الگوریتم مینی مکس کسب کنیم.</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a80b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "import time\n",
    "import turtle\n",
    "NEG_INFINITY = -1000\n",
    "POS_INFINITY = 1000\n",
    "explored_nodes = 0\n",
    "n = 0\n",
    "m = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c05066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OthelloUI:\n",
    "    def __init__(self, board_size=6, square_size=60):\n",
    "        self.board_size = board_size\n",
    "        self.square_size = square_size\n",
    "        self.screen = turtle.Screen()\n",
    "        self.screen.setup(self.board_size * self.square_size + 50, self.board_size * self.square_size + 50)\n",
    "        self.screen.bgcolor('white')\n",
    "        self.screen.title('Othello')\n",
    "        self.pen = turtle.Turtle()\n",
    "        self.pen.hideturtle()\n",
    "        self.pen.speed(0)\n",
    "        turtle.tracer(0, 0)\n",
    "        \n",
    "\n",
    "    def draw_board(self, board):\n",
    "        self.pen.penup()\n",
    "        x, y = -self.board_size / 2 * self.square_size, self.board_size / 2 * self.square_size\n",
    "        for i in range(self.board_size):\n",
    "            self.pen.penup()\n",
    "            for j in range(self.board_size):\n",
    "                self.pen.goto(x + j * self.square_size, y - i * self.square_size)\n",
    "                self.pen.pendown()\n",
    "                self.pen.fillcolor('green')\n",
    "                self.pen.begin_fill()\n",
    "                self.pen.setheading(0)\n",
    "                for _ in range(4):\n",
    "                    self.pen.forward(self.square_size)\n",
    "                    self.pen.right(90)\n",
    "                self.pen.penup()\n",
    "                self.pen.end_fill()\n",
    "                self.pen.goto(x + j * self.square_size + self.square_size / 2,\n",
    "                              y - i * self.square_size - self.square_size + 5)\n",
    "                if board[i][j] == 1:\n",
    "                    self.pen.fillcolor('white')\n",
    "                    self.pen.begin_fill()\n",
    "                    self.pen.circle(self.square_size / 2 - 5)\n",
    "                    self.pen.end_fill()\n",
    "                elif board[i][j] == -1:\n",
    "                    self.pen.fillcolor('black')\n",
    "                    self.pen.begin_fill()\n",
    "                    self.pen.circle(self.square_size / 2 - 5)\n",
    "                    self.pen.end_fill()\n",
    "\n",
    "        turtle.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1362e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Othello:\n",
    "    def __init__(self, ui, minimax_depth=1, prune=True):\n",
    "        self.size = 6\n",
    "        self.ui = OthelloUI(self.size) if ui else None\n",
    "        self.board = [[0 for _ in range(self.size)] for _ in range(self.size)]\n",
    "        self.board[int(self.size / 2) - 1][int(self.size / 2) - 1] = self.board[int(self.size / 2)][\n",
    "            int(self.size / 2)] = 1\n",
    "        self.board[int(self.size / 2) - 1][int(self.size / 2)] = self.board[int(self.size / 2)][\n",
    "            int(self.size / 2) - 1] = -1\n",
    "        self.current_turn = random.choice([1, -1])\n",
    "        self.changedPieces = {}\n",
    "        self.minimax_depth = minimax_depth\n",
    "        self.prune = prune\n",
    "        self.best_move = {}\n",
    "\n",
    "    def set_board(self, new_board):\n",
    "        self.board = new_board\n",
    "\n",
    "    def get_winner(self):\n",
    "        white_count = sum([row.count(1) for row in self.board])\n",
    "        black_count = sum([row.count(-1) for row in self.board])\n",
    "        if white_count > black_count:\n",
    "            return 1\n",
    "        elif white_count < black_count:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def calc_prioritiy(self,key):\n",
    "        i, j = key\n",
    "        for x in [0, 5]:\n",
    "            for y in [0, 5]:\n",
    "                if (i,j) == (x,y):\n",
    "                    return 1\n",
    "            for y in [1,2,3,4]:\n",
    "                if (i,j) == (x,y) or (i,j) == (y,x):\n",
    "                    return 2\n",
    "        return 3\n",
    "\n",
    "    def get_valid_moves(self, player):\n",
    "        moves = set()\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if self.board[i][j] == 0:\n",
    "                    for di in [-1, 0, 1]:\n",
    "                        for dj in [-1, 0, 1]:\n",
    "                            if di == 0 and dj == 0:\n",
    "                                continue\n",
    "                            x, y = i, j\n",
    "                            captured = []\n",
    "                            while 0 <= x + di < self.size and 0 <= y + dj < self.size and self.board[x + di][\n",
    "                                    y + dj] == -player:\n",
    "                                captured.append((x + di, y + dj))\n",
    "                                x += di\n",
    "                                y += dj\n",
    "                            if 0 <= x + di < self.size and 0 <= y + dj < self.size and self.board[x + di][\n",
    "                                    y + dj] == player and len(captured) > 0:\n",
    "                                moves.add((i, j))\n",
    "        return list(moves)\n",
    "\n",
    "    def make_move(self, player, move):\n",
    "        i, j = move\n",
    "        changed = [move]\n",
    "        self.board[i][j] = player\n",
    "        for di in [-1, 0, 1]:\n",
    "            for dj in [-1, 0, 1]:\n",
    "                if di == 0 and dj == 0:\n",
    "                    continue\n",
    "                x, y = i, j\n",
    "                captured = []\n",
    "                while 0 <= x + di < self.size and 0 <= y + dj < self.size and self.board[x + di][y + dj] == -player:\n",
    "                    captured.append((x + di, y + dj))\n",
    "                    x += di\n",
    "                    y += dj\n",
    "                if 0 <= x + di < self.size and 0 <= y + dj < self.size and self.board[x + di][y + dj] == player:\n",
    "                    for (cx, cy) in captured:\n",
    "                        self.board[cx][cy] = player\n",
    "                        changed.append((cx, cy))\n",
    "        return changed\n",
    "\n",
    "    def get_cpu_move(self):\n",
    "        moves = self.get_valid_moves(-1)\n",
    "        if len(moves) == 0:\n",
    "            return None\n",
    "        return random.choice(moves)\n",
    "\n",
    "    def evaluate(self):\n",
    "        white_count, black_count = 0, 0\n",
    "        for i in range(0,6):\n",
    "            for j in range(0,6):\n",
    "                if self.board[i][j] == 1:\n",
    "                    white_count += 1\n",
    "                    if i == 0 or i == 5:\n",
    "                        white_count += 1\n",
    "                    if j == 0 or j == 5:\n",
    "                        white_count += 1\n",
    "                elif self.board[i][j] == -1:\n",
    "                    black_count += 1\n",
    "                    if i == 0 or i == 5:\n",
    "                        black_count += 1\n",
    "                    if j == 0 or j == 5:\n",
    "                        black_count += 1\n",
    "        return white_count - black_count\n",
    "\n",
    "    def retrackBoard(self, depth):\n",
    "        x,y = self.changedPieces[depth].pop(0)\n",
    "        self.board[x][y] = 0\n",
    "        for x,y in self.changedPieces[depth]:\n",
    "            self.board[x][y] = -self.board[x][y]\n",
    "\n",
    "    def max_val(self, depth, alpha, beta):\n",
    "        global explored_nodes, n\n",
    "        if depth < 0:\n",
    "            return self.evaluate()\n",
    "        moves = self.get_valid_moves(1)\n",
    "        if moves == []:\n",
    "            return self.evaluate()\n",
    "        max_till_now = alpha\n",
    "        for move in moves:\n",
    "            self.changedPieces[depth] = self.make_move(1, move)\n",
    "            explored_nodes += 1\n",
    "            val = self.min_val(depth - 1, alpha, beta) \n",
    "            if val > max_till_now:\n",
    "                max_till_now = val\n",
    "                self.best_move[depth] = move\n",
    "            if self.prune and max_till_now >= beta:\n",
    "                n += 1\n",
    "                self.retrackBoard(depth)\n",
    "                return max_till_now\n",
    "            alpha = max(max_till_now, alpha)\n",
    "            self.retrackBoard(depth)\n",
    "    \n",
    "        return max_till_now\n",
    "\n",
    "    def min_val(self, depth, alpha, beta):\n",
    "        global explored_nodes, m\n",
    "        if depth < 0:\n",
    "            return self.evaluate()\n",
    "        moves = self.get_valid_moves(-1)\n",
    "        if moves == []:\n",
    "            return self.evaluate()\n",
    "        min_till_now = beta\n",
    "        for move in moves:\n",
    "            self.changedPieces[depth] = self.make_move(-1, move)\n",
    "            explored_nodes += 1\n",
    "            val = self.max_val(depth - 1, alpha, beta)\n",
    "            if val < min_till_now:\n",
    "                min_till_now = val\n",
    "                self.best_move[depth] = move\n",
    "            if self.prune and min_till_now <= alpha:\n",
    "                m += 1\n",
    "                self.retrackBoard(depth)\n",
    "                return min_till_now\n",
    "            beta = min(min_till_now, beta)\n",
    "            self.retrackBoard(depth)\n",
    "        return min_till_now\n",
    "\n",
    "    def get_human_move(self):\n",
    "        moves = self.get_valid_moves(1)\n",
    "        if len(moves) == 0:\n",
    "            return None\n",
    "        self.max_val(depth = self.minimax_depth, alpha = NEG_INFINITY, beta = POS_INFINITY)\n",
    "        return self.best_move[self.minimax_depth]\n",
    "\n",
    "    def terminal_test(self):\n",
    "        return len(self.get_valid_moves(1)) == 0 and len(self.get_valid_moves(-1)) == 0\n",
    "\n",
    "    def play(self):\n",
    "        winner = None\n",
    "        while not self.terminal_test() :\n",
    "            if self.ui:\n",
    "                self.ui.draw_board(self.board)\n",
    "            if self.current_turn == 1:\n",
    "                move = self.get_human_move()\n",
    "                if move:\n",
    "                    self.make_move(self.current_turn, move)\n",
    "            else:\n",
    "                move = self.get_cpu_move()\n",
    "                if move:\n",
    "                    self.make_move(self.current_turn, move)\n",
    "            self.current_turn = -self.current_turn\n",
    "            if self.ui:\n",
    "                self.ui.draw_board(self.board)\n",
    "                time.sleep(0.1)\n",
    "        winner = self.get_winner()\n",
    "        return winner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145bb33",
   "metadata": {},
   "source": [
    "<H2 style=\"color:green;font-size:20px;\"align=\"right\">Evaluate function   </H2> \n",
    "<H2 style=\"color:black;font-size:15px;\"align=\"right\"> در این تابع امتیاز صفحه کنونی را ارزیابی می کنیم. ارزیابی به این صورت است که برای مهره های چهار گوشه صفحه امتیاز 3، برای اطراف صفحه امتیاز 2 \n",
    "و برای مهره های داخلی امنیازی 3 را برای هر رنگ لحاظ می کنیم. این تفاوت به این خاطر است که با توجه به منطق بازی ، رنگی که گوشه ها را دارد درادامه احتمال موفقیت بیشتری دارد.     </H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a008d8d7",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\">چه مواردی را هنگام محاسبه هیوریستیک در نظر گرفتید؟ چرا؟ </H3>\n",
    "<H3 style=\"color:black;font-size:20px;\"align=\"right\">با توجه به منطق بازی اتلو، رنگی که گوشه ها را در اختیار داشته باشد، احتمالا تا انتهای بازی مهره های همرنگ بیشتری خواهد داشت.پس برای مهره ها در چهار گوشه صفحه ضریب 3، برای مهره های دور صفحه، ضریب 2 و برای باقی مهره ها ضریب 1 در نظر می گیریم و جمع وزندار مهره های سفید منهای سیاه را به عنوان هیوریستیک بر می گردانیم، </H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99885c4",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\"> صد بار تست ، عمق یک </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8555a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1\n",
      "human:  0.87\n",
      "cpu:  0.11\n",
      "mean explored nodes:  439.88\n",
      "--- 2.5398101806640625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "explored_nodes = 0\n",
    "RANGE = 100\n",
    "depth = 1\n",
    "alpha_beta_prune = 0\n",
    "test = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(RANGE):\n",
    "    otl = Othello(0, depth, alpha_beta_prune)\n",
    "    winner = otl.play()\n",
    "    test.append(winner)\n",
    "\n",
    "human_win = test.count(1)\n",
    "cpu_win = test.count(-1)\n",
    "equal = test.count(0)\n",
    "print(\"depth: \", depth)\n",
    "print(\"human: \",human_win/RANGE)\n",
    "print(\"cpu: \",cpu_win/RANGE)\n",
    "print(\"mean explored nodes: \", explored_nodes/RANGE)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f499d8be",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\"> صد بار تست ، عمق سه </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ceb7ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3\n",
      "human:  0.95\n",
      "cpu:  0.04\n",
      "mean explored nodes:  16776.12\n",
      "--- 44.69069147109985 seconds ---\n"
     ]
    }
   ],
   "source": [
    "explored_nodes = 0\n",
    "RANGE = 100\n",
    "depth = 3\n",
    "alpha_beta_prune = 0\n",
    "test = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(RANGE):\n",
    "    otl = Othello(0, depth, alpha_beta_prune)\n",
    "    winner = otl.play()\n",
    "    test.append(winner)\n",
    "\n",
    "human_win = test.count(1)\n",
    "cpu_win = test.count(-1)\n",
    "equal = test.count(0)\n",
    "print(\"depth: \", depth)\n",
    "print(\"human: \",human_win/RANGE)\n",
    "print(\"cpu: \",cpu_win/RANGE)\n",
    "print(\"mean explored nodes: \", explored_nodes/RANGE)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d31530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5\n",
      "human:  0.98\n",
      "cpu:  0.02\n",
      "mean explored nodes:  729416.91\n",
      "--- 1842.3831896781921 seconds ---\n"
     ]
    }
   ],
   "source": [
    "explored_nodes = 0\n",
    "RANGE = 100\n",
    "depth = 5\n",
    "alpha_beta_prune = 0\n",
    "test = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(RANGE):\n",
    "    otl = Othello(0, depth, alpha_beta_prune)\n",
    "    winner = otl.play()\n",
    "    test.append(winner)\n",
    "\n",
    "human_win = test.count(1)\n",
    "cpu_win = test.count(-1)\n",
    "equal = test.count(0)\n",
    "print(\"depth: \", depth)\n",
    "print(\"human: \",human_win/RANGE)\n",
    "print(\"cpu: \",cpu_win/RANGE)\n",
    "print(\"mean explored nodes: \", explored_nodes/RANGE)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab19b458",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\">عمق الگوریتم چه رابطه ای با شانس پیروزی، زمان اجرا و تعداد گره های دیده شده دارد ؟ </H3>\n",
    "<H3 style=\"color:black;font-size:20px;\"align=\"right\">هر چه تا عمق بیشتری را بررسی کنیم، پیش بینی و آینده نگری بهتری در بازی داریم و لذا همانطور که می بینید شانس پیروزی افزایش می یابد ولی چون باید سطوح بیشتری در درخت جست و جو را طی کنیم، زمان اجرا و تعداد گره های دیده شده به مراتب بیشتر می شوند. البته این موضوع که ما درنظر گرفتیم حریف بهینه عمل می کند ولی در حقیقت رندوم عمل می کند، می تواند در بعضی شرایط پیروزی ما را عقب بیندازد یا از امتیاز نهاییمان بکاهد و در این شرایط که حریف بهینه عمل نمی کند، اعمال شانس در مواقعی که پای امتیاز زیادی برای ما در میان است، می تواند به برد ما کمک شایانی کند  </H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1c7cb",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\"> صد بار تست ، عمق یک ، با هرس الفا بتا </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab5c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1\n",
      "human:  0.81\n",
      "cpu:  0.17\n",
      "mean explored nodes:  297.87\n",
      "--- 1.468074083328247 seconds ---\n"
     ]
    }
   ],
   "source": [
    "explored_nodes = 0\n",
    "RANGE = 100\n",
    "depth = 1\n",
    "alpha_beta_prune = 1\n",
    "test = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(RANGE):\n",
    "    otl = Othello(0, depth, alpha_beta_prune)\n",
    "    winner = otl.play()\n",
    "    test.append(winner)\n",
    "\n",
    "human_win = test.count(1)\n",
    "cpu_win = test.count(-1)\n",
    "equal = test.count(0)\n",
    "print(\"depth: \", depth)\n",
    "print(\"human: \",human_win/RANGE)\n",
    "print(\"cpu: \",cpu_win/RANGE)\n",
    "print(\"mean explored nodes: \", explored_nodes/RANGE)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6171535",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\"> صد بار تست ، عمق سه ، با هرس الفا بتا </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd8239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3\n",
      "human:  0.95\n",
      "cpu:  0.04\n",
      "mean explored nodes:  4384.27\n",
      "--- 16.147605419158936 seconds ---\n"
     ]
    }
   ],
   "source": [
    "RANGE = 100\n",
    "depth = 3\n",
    "explored_nodes = 0\n",
    "alpha_beta_prune = 1\n",
    "test = []\n",
    "start_time = time.time()\n",
    "for i in range(RANGE):\n",
    "    otl = Othello(0, depth, alpha_beta_prune)\n",
    "    winner = otl.play()\n",
    "    # print(winner)\n",
    "    test.append(winner)\n",
    "\n",
    "human_win = test.count(1)\n",
    "cpu_win = test.count(-1)\n",
    "equal = test.count(0)\n",
    "print(\"depth: \", depth)\n",
    "print(\"human: \",human_win/RANGE)\n",
    "print(\"cpu: \",cpu_win/RANGE)\n",
    "print(\"mean explored nodes: \", explored_nodes/RANGE)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6801b325",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\"> صد بار تست ، عمق پنج ، با هرس الفا بتا </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0e73ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5\n",
      "human:  0.99\n",
      "cpu:  0.0\n",
      "mean explored nodes:  60880.92\n",
      "--- 225.53159880638123 seconds ---\n"
     ]
    }
   ],
   "source": [
    "RANGE = 100\n",
    "depth = 5\n",
    "explored_nodes = 0\n",
    "alpha_beta_prune = 1\n",
    "test = []\n",
    "start_time = time.time()\n",
    "for i in range(RANGE):\n",
    "    otl = Othello(0, depth, alpha_beta_prune)\n",
    "    winner = otl.play()\n",
    "    # print(winner)\n",
    "    test.append(winner)\n",
    "\n",
    "human_win = test.count(1)\n",
    "cpu_win = test.count(-1)\n",
    "equal = test.count(0)\n",
    "print(\"depth: \", depth)\n",
    "print(\"human: \",human_win/RANGE)\n",
    "print(\"cpu: \",cpu_win/RANGE)\n",
    "print(\"mean explored nodes: \", explored_nodes/RANGE)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75564ddd",
   "metadata": {},
   "source": [
    "<H3 style=\"color:blue;font-size:20px;\"align=\"right\"> صد بار تست ، عمق هفت ، با هرس الفا بتا </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecee1ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  7\n",
      "human:  1.0\n",
      "cpu:  0.0\n",
      "mean explored nodes:  753423.22\n",
      "--- 2940.5134358406067 seconds ---\n"
     ]
    }
   ],
   "source": [
    "RANGE = 100\n",
    "depth = 7\n",
    "explored_nodes = 0\n",
    "alpha_beta_prune = 1\n",
    "test = []\n",
    "start_time = time.time()\n",
    "for i in range(RANGE):\n",
    "    otl = Othello(0, depth, alpha_beta_prune)\n",
    "    winner = otl.play()\n",
    "    # print(winner)\n",
    "    test.append(winner)\n",
    "\n",
    "human_win = test.count(1)\n",
    "cpu_win = test.count(-1)\n",
    "equal = test.count(0)\n",
    "print(\"depth: \", depth)\n",
    "print(\"human: \",human_win/RANGE)\n",
    "print(\"cpu: \",cpu_win/RANGE)\n",
    "print(\"mean explored nodes: \", explored_nodes/RANGE)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f284ac",
   "metadata": {},
   "source": [
    "<H3 style=\"color:black;font-size:20px;\"align=\"right\">همانطور که می بینید، استفاده از هرس الفا بتا دقت را حفظ کرده و تعداد نود های دیده شده به مقدار قابل ملاحظه ای کم شده و مطابق انتظار زمان اجرا هم کاهش یافته است </H3>\n",
    "<H3 style=\"color:green;font-size:20px;\"align=\"right\">نتیجه گیری کلی</H3>\n",
    "<H3 style=\"color:black;font-size:20px;\"align=\"right\">دیدیم که استفاده از الگوریتم مینی مکس می تواند یک استراتژی برد در بازی های خصمانه برای ما تولید کند. که با افزایش عمق و به عبارتی دوراندیشی الگوریتم سرچ آن می توان احتمال برد را به قیمت زیاد شدن زمان اجرا و نود های بررسی شده ، افزایش داد. البته برای کاهش تعداد نود های اضافه بررسی شده که تاثیری در دقت الگوریتم ندارند ولی زمان اجرا را زیاد می کنند ، می توان از هرس الفا بتا استفاده کرد که از محاسبه اضافه جلوگیری می کند </H3>\n",
    "<H3 style=\"color:green;font-size:20px;\"align=\"right\">منابع</H3>\n",
    "<H3 style=\"color:black;font-size:15px;\"align=\"right\">https://github.com/Sara-Rezaeimanesh/Checkers_Playing_Agents</H3>\n",
    "<H3 style=\"color:black;font-size:15px;\"align=\"right\">https://github.com/nargesi-gholami/Artificial-Intelligence-projects/tree/main/AI_CA3_min_max</H3>\n",
    "<H3 style=\"color:black;font-size:15px;\"align=\"right\">https://blog.devgenius.io/simple-min-max-chess-ai-in-python-2910a3602641#:~:text=Min%20Max%20is%20a%20search,the%20value%20for%20the%20opponent.</H3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
